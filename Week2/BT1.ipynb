{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b58f2e08",
   "metadata": {},
   "source": [
    "# Bài tập 1. \n",
    "Cho đầu vào là 1 văn bản tiếng Anh hoặc Việt (độ dài >1000 từ), (có thể lấy bài báo trên mạng). Hãy tách và thống kê tần số xuất hiện của các 2-gram, 3-gram và 4-gram (không phân biệt chữ hoa, thường). 2-gram là nhóm 2 từ liên tiếp, 3-gram là nhóm 3 từ liên tiếp,..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8e64dd",
   "metadata": {},
   "source": [
    "### Tiền xử lý văn bản\n",
    "-  Chuyển toàn bộ văn bản về chữ thường (lowercase)\n",
    "- Loại bỏ tất cả các dấu câu, thay thế chúng bằng một khoảng trắng."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f077f5f",
   "metadata": {},
   "source": [
    "### Tách từ (Tokenization)\n",
    "Sau khi đã có văn bản sạch, cần tách chuỗi văn bản dài thành một danh sách (list) các từ riêng lẻ.\n",
    "\n",
    "Các từ được ngăn cách bởi khoảng trắng. Sử dụng phương thức split() của chuỗi trong Python. Nó sẽ tự động tách chuỗi tại các khoảng trắng và trả về một list các từ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2e2c12",
   "metadata": {},
   "source": [
    "### Tạo N-gram\n",
    "\n",
    "*Từ danh sách các từ đã tách, làm thế nào để tạo ra các n-gram? sử dụng kỹ thuật \"cửa sổ trượt\" (sliding window).\n",
    "\n",
    "Để tạo 2-gram, cửa sổ có kích thước là 2. Nó sẽ trượt qua danh sách từ:\n",
    "\n",
    "- Lấy từ [0] và [1].\n",
    "\n",
    "- Trượt sang phải, lấy từ [1] và [2].\n",
    "\n",
    "...\n",
    "\n",
    "- Trượt đến cuối, lấy từ [n-2] và [n-1].\n",
    "\n",
    "Tương tự cho 3-gram (cửa sổ kích thước 3) và 4-gram (cửa sổ kích thước 4).\n",
    "\n",
    "*Cấu trúc dữ liệu để lưu n-gram: Mỗi n-gram là một nhóm các từ. Dùng Tuple vì:\n",
    "\n",
    "- Tuple là bất biến (immutable), nên nó có thể được dùng làm khóa (key) trong một Dictionary.\n",
    "- Nó thể hiện rõ ràng một nhóm các phần tử có thứ tự."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8acf08",
   "metadata": {},
   "source": [
    "### Thống kê tần số\n",
    "\n",
    "Sau khi đã tạo được một danh sách tất cả các n-gram, chúng ta cần đếm chúng.\n",
    "Làm sao để đếm số lần xuất hiện của mỗi tuple n-gram một cách hiệu quả? Giải pháp: Sử dụng Dictionary.\n",
    "- Key: Chính là tuple n-gram (ví dụ: ('trí', 'tuệ')).\n",
    "- Value: Số lần xuất hiện của n-gram đó.\n",
    "\n",
    "* Thuật toán đếm:\n",
    "- Tạo một dictionary rỗng, gọi là counts.\n",
    "- Duyệt qua danh sách các n-gram đã tạo ở bước 3.\n",
    "- Với mỗi ngram:\n",
    "    -   Nếu ngram đã có trong counts, tăng giá trị của nó lên 1.\n",
    "    -   Nếu ngram chưa có, thêm nó vào counts với giá trị là 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b0ecbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def thong_ke_ngram(van_ban, n):\n",
    "    \"\"\"\n",
    "    Tách và thống kê tần số xuất hiện của n-gram trong một văn bản.\n",
    "\n",
    "    Args:\n",
    "        van_ban (str): Chuỗi văn bản đầu vào.\n",
    "        n (int): Kích thước của gram (ví dụ: 2 cho 2-gram).\n",
    "\n",
    "    Returns:\n",
    "        collections.Counter: Một đối tượng Counter (giống dictionary) \n",
    "                             chứa các n-gram và tần số của chúng.\n",
    "    \"\"\"\n",
    "    # Bước 1: Tiền xử lý văn bản\n",
    "    # Chuyển về chữ thường\n",
    "    van_ban_lower = van_ban.lower()\n",
    "    # Loại bỏ tất cả các ký tự không phải là chữ cái, số, hoặc khoảng trắng tiếng Việt\n",
    "    # Điều này giúp loại bỏ dấu câu.\n",
    "    van_ban_sach = re.sub(r'[^\\w\\s]', '', van_ban_lower)\n",
    "\n",
    "    # Bước 2: Tách từ (Tokenization)\n",
    "    cac_tu = van_ban_sach.split()\n",
    "\n",
    "    # Bước 3: Tạo N-gram\n",
    "    # Dùng list comprehension để tạo một danh sách các tuple n-gram\n",
    "    ngrams = [tuple(cac_tu[i:i+n]) for i in range(len(cac_tu) - n + 1)]\n",
    "    \n",
    "    # Bước 4: Thống kê tần số \"from scratch\"\n",
    "    tan_so = {}\n",
    "    for ngram in ngrams:\n",
    "    # 3. Kiểm tra sự tồn tại\n",
    "        if ngram in tan_so:\n",
    "        # Nếu có rồi, tăng số đếm\n",
    "            tan_so[ngram] += 1\n",
    "        else:\n",
    "        # Nếu chưa có, khởi tạo số đếm là 1\n",
    "            tan_so[ngram] = 1\n",
    "    return tan_so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdebf30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cách khác để đếm tần số\n",
    "def dem_tan_so_bang_get(ngrams):\n",
    "    tan_so = {}\n",
    "    for ngram in ngrams:\n",
    "        tan_so[ngram] = tan_so.get(ngram, 0) + 1\n",
    "    return tan_so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d2bd641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('trí', 'tuệ'): 3, ('tuệ', 'nhân'): 2, ('nhân', 'tạo'): 2, ('tạo', 'ai'): 1, ('ai', 'là'): 1, ('là', 'một'): 1, ('một', 'lĩnh'): 1, ('lĩnh', 'vực'): 1, ('vực', 'của'): 1, ('của', 'khoa'): 1, ('khoa', 'học'): 1, ('học', 'máy'): 1, ('máy', 'tính'): 2, ('tính', 'tập'): 1, ('tập', 'trung'): 1, ('trung', 'vào'): 1, ('vào', 'việc'): 1, ('việc', 'tạo'): 1, ('tạo', 'ra'): 1, ('ra', 'các'): 1, ('các', 'hệ'): 1, ('hệ', 'thống'): 1, ('thống', 'máy'): 1, ('tính', 'có'): 1, ('có', 'khả'): 1, ('khả', 'năng'): 1, ('năng', 'thực'): 1, ('thực', 'hiện'): 1, ('hiện', 'các'): 1, ('các', 'tác'): 1, ('tác', 'vụ'): 1, ('vụ', 'thường'): 1, ('thường', 'đòi'): 1, ('đòi', 'hỏi'): 1, ('hỏi', 'trí'): 1, ('tuệ', 'của'): 1, ('của', 'con'): 1, ('con', 'người'): 1, ('người', 'trí'): 1, ('tạo', 'đang'): 1, ('đang', 'phát'): 1, ('phát', 'triển'): 1, ('triển', 'nhanh'): 1, ('nhanh', 'chóng'): 1, ('chóng', 'và'): 1, ('và', 'có'): 1, ('có', 'nhiều'): 1, ('nhiều', 'ứng'): 1, ('ứng', 'dụng'): 1}\n"
     ]
    }
   ],
   "source": [
    "# --- VÍ DỤ MINH HỌA ---\n",
    "van_ban_mau = \"\"\"\n",
    "Trí tuệ nhân tạo (AI) là một lĩnh vực của khoa học máy tính, tập trung vào việc tạo ra \n",
    "các hệ thống máy tính có khả năng thực hiện các tác vụ thường đòi hỏi trí tuệ của con người. \n",
    "Trí tuệ nhân tạo đang phát triển nhanh chóng và có nhiều ứng dụng.\n",
    "\"\"\"\n",
    "\n",
    "tan_so_2gram = thong_ke_ngram(van_ban_mau, 2)\n",
    "print(tan_so_2gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db8f3e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('trí', 'tuệ', 'nhân'): 2, ('tuệ', 'nhân', 'tạo'): 2, ('nhân', 'tạo', 'ai'): 1, ('tạo', 'ai', 'là'): 1, ('ai', 'là', 'một'): 1, ('là', 'một', 'lĩnh'): 1, ('một', 'lĩnh', 'vực'): 1, ('lĩnh', 'vực', 'của'): 1, ('vực', 'của', 'khoa'): 1, ('của', 'khoa', 'học'): 1, ('khoa', 'học', 'máy'): 1, ('học', 'máy', 'tính'): 1, ('máy', 'tính', 'tập'): 1, ('tính', 'tập', 'trung'): 1, ('tập', 'trung', 'vào'): 1, ('trung', 'vào', 'việc'): 1, ('vào', 'việc', 'tạo'): 1, ('việc', 'tạo', 'ra'): 1, ('tạo', 'ra', 'các'): 1, ('ra', 'các', 'hệ'): 1, ('các', 'hệ', 'thống'): 1, ('hệ', 'thống', 'máy'): 1, ('thống', 'máy', 'tính'): 1, ('máy', 'tính', 'có'): 1, ('tính', 'có', 'khả'): 1, ('có', 'khả', 'năng'): 1, ('khả', 'năng', 'thực'): 1, ('năng', 'thực', 'hiện'): 1, ('thực', 'hiện', 'các'): 1, ('hiện', 'các', 'tác'): 1, ('các', 'tác', 'vụ'): 1, ('tác', 'vụ', 'thường'): 1, ('vụ', 'thường', 'đòi'): 1, ('thường', 'đòi', 'hỏi'): 1, ('đòi', 'hỏi', 'trí'): 1, ('hỏi', 'trí', 'tuệ'): 1, ('trí', 'tuệ', 'của'): 1, ('tuệ', 'của', 'con'): 1, ('của', 'con', 'người'): 1, ('con', 'người', 'trí'): 1, ('người', 'trí', 'tuệ'): 1, ('nhân', 'tạo', 'đang'): 1, ('tạo', 'đang', 'phát'): 1, ('đang', 'phát', 'triển'): 1, ('phát', 'triển', 'nhanh'): 1, ('triển', 'nhanh', 'chóng'): 1, ('nhanh', 'chóng', 'và'): 1, ('chóng', 'và', 'có'): 1, ('và', 'có', 'nhiều'): 1, ('có', 'nhiều', 'ứng'): 1, ('nhiều', 'ứng', 'dụng'): 1}\n"
     ]
    }
   ],
   "source": [
    "tan_so_3gram = thong_ke_ngram(van_ban_mau, 3)\n",
    "print(tan_so_3gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69ebdbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('trí', 'tuệ', 'nhân', 'tạo'): 2, ('tuệ', 'nhân', 'tạo', 'ai'): 1, ('nhân', 'tạo', 'ai', 'là'): 1, ('tạo', 'ai', 'là', 'một'): 1, ('ai', 'là', 'một', 'lĩnh'): 1, ('là', 'một', 'lĩnh', 'vực'): 1, ('một', 'lĩnh', 'vực', 'của'): 1, ('lĩnh', 'vực', 'của', 'khoa'): 1, ('vực', 'của', 'khoa', 'học'): 1, ('của', 'khoa', 'học', 'máy'): 1, ('khoa', 'học', 'máy', 'tính'): 1, ('học', 'máy', 'tính', 'tập'): 1, ('máy', 'tính', 'tập', 'trung'): 1, ('tính', 'tập', 'trung', 'vào'): 1, ('tập', 'trung', 'vào', 'việc'): 1, ('trung', 'vào', 'việc', 'tạo'): 1, ('vào', 'việc', 'tạo', 'ra'): 1, ('việc', 'tạo', 'ra', 'các'): 1, ('tạo', 'ra', 'các', 'hệ'): 1, ('ra', 'các', 'hệ', 'thống'): 1, ('các', 'hệ', 'thống', 'máy'): 1, ('hệ', 'thống', 'máy', 'tính'): 1, ('thống', 'máy', 'tính', 'có'): 1, ('máy', 'tính', 'có', 'khả'): 1, ('tính', 'có', 'khả', 'năng'): 1, ('có', 'khả', 'năng', 'thực'): 1, ('khả', 'năng', 'thực', 'hiện'): 1, ('năng', 'thực', 'hiện', 'các'): 1, ('thực', 'hiện', 'các', 'tác'): 1, ('hiện', 'các', 'tác', 'vụ'): 1, ('các', 'tác', 'vụ', 'thường'): 1, ('tác', 'vụ', 'thường', 'đòi'): 1, ('vụ', 'thường', 'đòi', 'hỏi'): 1, ('thường', 'đòi', 'hỏi', 'trí'): 1, ('đòi', 'hỏi', 'trí', 'tuệ'): 1, ('hỏi', 'trí', 'tuệ', 'của'): 1, ('trí', 'tuệ', 'của', 'con'): 1, ('tuệ', 'của', 'con', 'người'): 1, ('của', 'con', 'người', 'trí'): 1, ('con', 'người', 'trí', 'tuệ'): 1, ('người', 'trí', 'tuệ', 'nhân'): 1, ('tuệ', 'nhân', 'tạo', 'đang'): 1, ('nhân', 'tạo', 'đang', 'phát'): 1, ('tạo', 'đang', 'phát', 'triển'): 1, ('đang', 'phát', 'triển', 'nhanh'): 1, ('phát', 'triển', 'nhanh', 'chóng'): 1, ('triển', 'nhanh', 'chóng', 'và'): 1, ('nhanh', 'chóng', 'và', 'có'): 1, ('chóng', 'và', 'có', 'nhiều'): 1, ('và', 'có', 'nhiều', 'ứng'): 1, ('có', 'nhiều', 'ứng', 'dụng'): 1}\n"
     ]
    }
   ],
   "source": [
    "tan_so_4gram = thong_ke_ngram(van_ban_mau, 4)\n",
    "print(tan_so_4gram)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
