{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2ea853f",
   "metadata": {},
   "source": [
    "# BT2\n",
    "Với đầu vào là 2 văn bản tiếng anh cùng 1 chủ đề, hãy thống kê số lượng các 2-gram và 3-gram trùng nhau giữa 2 văn bản (không phân biệt hoa, thường) theo 2 tiêu chí:\n",
    "Không tính các n-gram bị trùng lặp trong mỗi văn bản\n",
    "có tính các n-gram trùng lặp trong mỗi văn bản"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e77afe8",
   "metadata": {},
   "source": [
    "## Tư duy:\n",
    "Tìm Tập hợp các n-gram duy nhất của văn bản1 và tập hợp các n-gram duy nhất của văn bản2 \n",
    "Tìm xem có bao nhiêu n-gram chung trong hai tập hợp đó.\n",
    "--> sử dụng set và thao tác lấy phần giao của 2 tập hợp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435e1255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Phân tích 2-gram ---\n",
      "Tiêu chí A (Không tính trùng lặp): Có 8 2-gram duy nhất trùng nhau.\n",
      "Tiêu chí B (Có tính trùng lặp): Có tổng cộng 11 lần 2-gram trùng nhau.\n",
      "\n",
      "========================================\n",
      "\n",
      "--- Phân tích 3-gram ---\n",
      "Tiêu chí A (Không tính trùng lặp): Có 6 3-gram duy nhất trùng nhau.\n",
      "Tiêu chí B (Có tính trùng lặp): Có tổng cộng 7 lần 3-gram trùng nhau.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import collections\n",
    "\n",
    "def tao_ngram_list(van_ban, n):\n",
    "    \"\"\"\n",
    "    Hàm trợ giúp: Tiền xử lý văn bản và tạo ra một danh sách các n-gram.\n",
    "    \"\"\"\n",
    "    # Chuyển về chữ thường và loại bỏ dấu câu\n",
    "    van_ban_sach = re.sub(r'[^\\w\\s]', '', van_ban.lower())\n",
    "    # Tách thành list các từ\n",
    "    cac_tu = van_ban_sach.split()\n",
    "    # Tạo danh sách các n-gram\n",
    "    ngrams = [tuple(cac_tu[i:i+n]) for i in range(len(cac_tu) - n + 1)]\n",
    "    return ngrams\n",
    "\n",
    "def so_sanh_khong_trung_lap(text1, text2, n):\n",
    "    \"\"\"\n",
    "    Đếm số lượng n-gram duy nhất trùng nhau.\n",
    "    \"\"\"\n",
    "    ngrams1 = tao_ngram_list(text1, n)\n",
    "    ngrams2 = tao_ngram_list(text2, n)\n",
    "\n",
    "    # Chuyển thành set để loại bỏ trùng lặp nội bộ\n",
    "    set1 = set(ngrams1)\n",
    "    set2 = set(ngrams2)\n",
    "\n",
    "    # Tìm các n-gram chung bằng phép giao\n",
    "    cac_gram_chung = set1 & set2\n",
    "\n",
    "    # Kết quả là số lượng phần tử trong set giao\n",
    "    return len(cac_gram_chung)\n",
    "\n",
    "def so_sanh_co_trung_lap(text1, text2, n):\n",
    "    \"\"\"\n",
    "    Đếm tổng số lần xuất hiện trùng lặp của các n-gram.\n",
    "    \"\"\"\n",
    "    ngrams1 = tao_ngram_list(text1, n)\n",
    "    ngrams2 = tao_ngram_list(text2, n)\n",
    "\n",
    "    # Sử dụng Counter để đếm tần số trong mỗi văn bản\n",
    "    counter1 = collections.Counter(ngrams1)\n",
    "    counter2 = collections.Counter(ngrams2)\n",
    "\n",
    "    # Phép giao của hai Counter sẽ lấy số lần xuất hiện tối thiểu\n",
    "    giao_counter = counter1 & counter2\n",
    "\n",
    "    # Kết quả là tổng số đếm của tất cả các n-gram chung\n",
    "    return sum(giao_counter.values())\n",
    "\n",
    "\n",
    "# --- VÍ DỤ MINH HỌA ---\n",
    "\n",
    "# Lấy 2 văn bản mẫu về cùng chủ đề (Machine Learning)\n",
    "text_A = \"\"\"\n",
    "Machine learning is a subfield of artificial intelligence. The goal of machine learning \n",
    "is to understand the structure of data and fit that data into models. \n",
    "These models can then be used by people. Machine learning is a fascinating field.\n",
    "\"\"\"\n",
    "\n",
    "text_B = \"\"\"\n",
    "Artificial intelligence is a broad field of computer science. Machine learning is a\n",
    "key part of that field. The goal of machine learning is to create systems that can learn\n",
    "from data. People use these systems every day.\n",
    "\"\"\"\n",
    "\n",
    "# --- Chạy thống kê cho 2-gram ---\n",
    "print(\"--- Phân tích 2-gram ---\")\n",
    "so_luong_A = so_sanh_khong_trung_lap(text_A, text_B, 2)\n",
    "print(f\"Tiêu chí A (Không tính trùng lặp): Có {so_luong_A} 2-gram duy nhất trùng nhau.\")\n",
    "\n",
    "so_luong_B = so_sanh_co_trung_lap(text_A, text_B, 2)\n",
    "print(f\"Tiêu chí B (Có tính trùng lặp): Có tổng cộng {so_luong_B} lần 2-gram trùng nhau.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*40 + \"\\n\")\n",
    "\n",
    "# --- Chạy thống kê cho 3-gram ---\n",
    "print(\"--- Phân tích 3-gram ---\")\n",
    "so_luong_A_3 = so_sanh_khong_trung_lap(text_A, text_B, 3)\n",
    "print(f\"Tiêu chí A (Không tính trùng lặp): Có {so_luong_A_3} 3-gram duy nhất trùng nhau.\")\n",
    "\n",
    "so_luong_B_3 = so_sanh_co_trung_lap(text_A, text_B, 3)\n",
    "print(f\"Tiêu chí B (Có tính trùng lặp): Có tổng cộng {so_luong_B_3} lần 3-gram trùng nhau.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
